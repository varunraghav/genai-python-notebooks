{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a9376c9-41da-47fb-bd31-078e1fafcb41",
   "metadata": {},
   "source": [
    "## Install and import modules/libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "931b44a0-08ac-4647-9da3-6ff76b810741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /Users/varunraghav/anaconda3/envs/llms/lib/python3.11/site-packages (3.9.1)\n",
      "Requirement already satisfied: click in /Users/varunraghav/anaconda3/envs/llms/lib/python3.11/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /Users/varunraghav/anaconda3/envs/llms/lib/python3.11/site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/varunraghav/anaconda3/envs/llms/lib/python3.11/site-packages (from nltk) (2024.9.11)\n",
      "Requirement already satisfied: tqdm in /Users/varunraghav/anaconda3/envs/llms/lib/python3.11/site-packages (from nltk) (4.66.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e224891-27fe-4da1-ab6e-aa580b0a38a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pypdf in /Users/varunraghav/anaconda3/envs/llms/lib/python3.11/site-packages (5.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6737036b-d8e9-4c9b-b7ed-2d38191521cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "import glob\n",
    "from dotenv import load_dotenv\n",
    "import gradio as gr\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2883aee2-be17-40a6-854b-29c30a96c2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports for langchain, plotly and Chroma\n",
    "\n",
    "from langchain.document_loaders import DirectoryLoader, TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_chroma import Chroma\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd11c588-1e07-4d80-abc4-ac14ecaa6d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/varunraghav/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "910754ee-ad0f-4dc2-9998-a40c7c1616f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# price is a factor for our company, so we're going to use a low cost model\n",
    "\n",
    "MODEL = \"gpt-4o-mini\"\n",
    "db_name = \"polity_db\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6d4a309-0062-487a-b7c3-4537e5ccd540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables in a file called .env\n",
    "\n",
    "load_dotenv()\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY', 'your-key-if-not-using-env')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4c4da8-90dd-43bd-bfc2-6ffdea3e4974",
   "metadata": {},
   "source": [
    "## Load File and Split it into Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eec9becf-dc30-470c-afc6-56d7ca3caec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "pdf_path = 'Indian_polity.pdf'  # Update with your file path\n",
    "loader = PyPDFLoader(pdf_path)\n",
    "\n",
    "documents = loader.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77c15d05-ceca-4e4c-81a3-c3e24d08607f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "of seats for the scheduled caste s and scheduled tribes to ensure adequate\n",
      "representation to them.\n",
      "12. Universal Adult Franchise\n",
      "The Indian Constitution adopt s universal adult franchise as a basis of\n",
      "elections to the Lok Sabha and the state legislative assemblies. Every\n",
      "citizen who is not less than 18 years of age has a right to vote without any\n",
      "discrimination of caste, race, religion, sex, literacy , wealth and so on. The\n",
      "voting age was reduced to 18 years from 21 years in 1989 by the 61st\n",
      "Constitutional Amendment Act of 1988.\n",
      "The introduction of universal adult franchise by the Constitution-makers\n",
      "was a bold experiment and highly remarkable in view of the vast size of the\n",
      "country , its huge population, high poverty , social inequality and\n",
      "overwhelming illiteracy .14\n",
      "Universal adult franchise make s democracy broad-based, enhances the\n",
      "self-respect and prestige of the common people, upholds the principle of\n",
      "equality , enables minorities to protect their interests and opens up new\n",
      "hopes and vistas for weaker sections.\n",
      "13. Single Citizenship\n",
      "Though the Indian Constitutio n is federal and envisages a dual polity\n",
      "(Centre and states), it provides for only a single citizenship, that is, the\n",
      "Indian citizenship.\n",
      "In countries like USA, on the other hand, each person is not only a\n",
      "citizen of USA, but also a citizen of the particular state to which he belongs.\n",
      "Thus, he owes allegiance to both and enjoys dual sets of rights–one\n",
      "conferred by the National government and another by the state government.\n",
      "In India, all citizens irrespective of the state in which they are born or\n",
      "reside enjoy the same political and civil rights of citizenship all over the\n",
      "country and no discrimination is made between them.\n",
      "Despite the constitutional provision for a single citizenship and uniform\n",
      "rights for all the people, India has been witnessing the communal riots,\n",
      "class conflicts, caste wars, linguistic clashes and ethnic disputes. This\n",
      "means that the cherished goal of the Constitution-makers to build a united\n",
      "and integrated Indian nation has not been fully realised.\n"
     ]
    }
   ],
   "source": [
    "# Let's take a look at the 10th page of extracted text\n",
    "print(documents[100].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c5f60f68-8bbc-4789-803e-f9f621ede83d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Preface to the\n",
      "Sixth Edition\n",
      "I am pleased to place before the readers a thoroughly revised, enlar ged and\n",
      "updated edition of this widely read book on Indian Polity .\n",
      "In 2011  and 2013, the UPSC changed the pattern and syllabus of the\n",
      "preliminary and main examinations, respectively . Both times, the scope of\n",
      "Indian Polity has been consider ably increased. Hence, this new edition of\n",
      "the book is more relevant now and is aimed to meet the expanded needs of\n",
      "the aspirants.\n",
      "In the course of revision and updation of this edition of the book, various\n",
      "new developments related to the subject, like recent constitutional\n",
      "amendments, parliamentary legislations, executive decisions and supreme\n",
      "court judgments, have been taken into account.\n",
      "Changes in this Edition:\n",
      "1.  Addition of 6 new chapters.\n",
      "2.  Inclusion of 2017, 2018 and 2019 preliminary questions with\n",
      "answers.\n",
      "3.  Inclusion of 2016, 2017, 2018 and 2019 mains questions.\n",
      "4.  Updation of the year-wise break-up of the UPSC questions in the\n",
      "preliminary and main examinations.\n",
      "5.  Inclusion of additional updated information on a number of topics.\n",
      "6.  New items included in various chapters.\n",
      "New Chapters:\n",
      "1.  Goods and Services T ax Council\n",
      "2.  National Commission for Backward Classes\n",
      "3.  National Investigation Agency\n",
      "4.  National Disaster Management Authority\n",
      "5.  Role of Regional Parties' metadata={'source': 'Indian_polity.pdf', 'page': 11}\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "# Use a text splitter to split the document into manageable chunks. Chunk size has been kept at manageable levels\n",
    "text_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "# Display the 10th chunk for reference\n",
    "print(chunks[10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57a1915-6e7f-472b-abff-d5e1ee049845",
   "metadata": {},
   "source": [
    "## Create Embedding, Vectorstore and Setup RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98c2d0d3-737f-478d-a9fe-0a7d4bd1e7b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorstore created with 1546 documents\n"
     ]
    }
   ],
   "source": [
    "# Put the chunks of data into a Vector Store that associates a Vector Embedding with each chunk\n",
    "# Chroma is a popular open source Vector Database based on SQLLite\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# Delete if already exists\n",
    "\n",
    "if os.path.exists(db_name):\n",
    "    Chroma(persist_directory=db_name, embedding_function=embeddings).delete_collection()\n",
    "\n",
    "# Create vectorstore\n",
    "\n",
    "vectorstore = Chroma.from_documents(documents=chunks, embedding=embeddings, persist_directory=db_name)\n",
    "print(f\"Vectorstore created with {vectorstore._collection.count()} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f1c8e14b-5f3b-4219-8228-5d03988d3c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new Chat with OpenAI\n",
    "llm = ChatOpenAI(temperature=0.7, model_name=MODEL)\n",
    "\n",
    "# set up the conversation memory for the chat\n",
    "memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True)\n",
    "\n",
    "# the retriever is an abstraction over the VectorStore that will be used during RAG\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# putting it together: set up the conversation chain with the GPT 3.5 LLM, the vector store and memory\n",
    "conversation_chain = ConversationalRetrievalChain.from_llm(llm=llm, retriever=retriever, memory=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "51503f10-5c40-461f-81b4-7d978cd71238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fundamental Rights are a set of rights guaranteed by the Constitution that ensure individual freedom and equality for all persons, protecting them from arbitrary actions by the state and private individuals. They are enshrined in Part III of the Constitution and include rights such as the right to equality, freedom, and protection against exploitation, among others.\n"
     ]
    }
   ],
   "source": [
    "# Let's try a simple question\n",
    "\n",
    "query = \"Please explain what fundamental rights is in a couple of sentences\"\n",
    "result = conversation_chain.invoke({\"question\": query})\n",
    "print(result[\"answer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434cad30-6952-49d9-8736-a3607cd3b5fd",
   "metadata": {},
   "source": [
    "## Setup Chat Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32a9f89-4d8b-4d83-b7bc-36c3d5f29bbf",
   "metadata": {},
   "source": [
    "#### Using both conventional LLM \n",
    "\n",
    "\n",
    "1. The user's input (question) is tokenized into individual words. Stop words (common words like \"the\", \"is\", etc.) are filtered out using the NLTK stopwords corpus. The filtered query is then re-embedded into a vector space using the embeddings.embed_query(filtered_query) method.\n",
    "2. Both the query and document embeddings are normalized to unit length\n",
    "3. A similarity threshold is set at 0.8. If the maximum similarity score between the query and any document is less than 0.8, the chatbot assumes that the query is not content-specific and sends it directly to the general LLM for a response.\n",
    "4. If the similarity score is greater than or equal to 0.8, the chatbot assumes that the query is content-based and uses the Conversational Retrieval Chain (RAG) to generate the answer by retrieving relevant content from the vector store.\n",
    "\n",
    "##### This method ensures that casual or less content-relevant queries are handled by a general LLM, while more specific queries that match document content are handled using the retrieval mechanism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dc55cc22-0df3-4af6-b18e-bb6c8a775b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "def chat(question, history):\n",
    "    # Threshold for similarity score to determine if query is content-based\n",
    "    similarity_threshold = 0.8\n",
    "\n",
    "    \n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "    # Tokenize the query\n",
    "    query_tokens = word_tokenize(question.lower())\n",
    "    \n",
    "    # Filter out stop words\n",
    "    filtered_query = ' '.join([word for word in query_tokens if word not in stop_words])\n",
    "    \n",
    "    # Re-embed the filtered query\n",
    "    query_embedding = embeddings.embed_query(filtered_query)\n",
    "    \n",
    "    # Get embeddings for all documents\n",
    "    all_docs = vectorstore._collection.get()\n",
    "\n",
    "    doc_embeddings = vectorstore._collection.get(include=['embeddings'])['embeddings']\n",
    "\n",
    "    print(doc_embeddings[5])\n",
    "\n",
    "    # Normalize query embedding\n",
    "    query_embedding = query_embedding / np.linalg.norm(query_embedding)\n",
    "    \n",
    "    # Normalize document embeddings\n",
    "    doc_embeddings = [doc_embedding / np.linalg.norm(doc_embedding) for doc_embedding in doc_embeddings]\n",
    "    \n",
    "    # Calculate cosine similarity between query and document embeddings\n",
    "    similarities = [np.dot(query_embedding, doc_embedding) for doc_embedding in doc_embeddings]\n",
    "\n",
    "    # Check if maximum similarity score exceeds threshold\n",
    "    max_similarity = max(similarities)\n",
    "    print(max_similarity)\n",
    "    if max_similarity < similarity_threshold:\n",
    "        result = llm.invoke(question)\n",
    "        return result.content  # Access the content of the AIMessage\n",
    "    else:\n",
    "        # Content-based query, use ConversationalRetrievalChain\n",
    "        print(\"entered rag\")\n",
    "        result = conversation_chain.invoke({\"question\": question})\n",
    "        return result[\"answer\"]  # This remains the same for the RAG path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "87f4d918-59e2-49fa-9b49-f0f6f2c31987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7867\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7867/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/varunraghav/anaconda3/envs/llms/lib/python3.11/site-packages/gradio/analytics.py:106: UserWarning: IMPORTANT: You are using gradio version 4.44.0, however version 4.44.1 is available, please upgrade. \n",
      "--------\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "view = gr.ChatInterface(chat).launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0697dba1-4cb3-4bb3-a16b-292b449e9760",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
